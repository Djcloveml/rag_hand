{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader  # type: ignore\n",
    "from typing import List\n",
    "from langchain.schema import Document\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ollama_query(context, question):\n",
    "    template = \"\"\"\n",
    "    You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "    Question: {question} \n",
    "    Context: {context} \n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "    model = OllamaLLM(model=\"qwen2.5:7b\")\n",
    "    chain = prompt | model | StrOutputParser()\n",
    "    response = chain.invoke({\"question\": question, \"context\": context})\n",
    "\n",
    "    # 过滤掉<think>...</think>部分\n",
    "\n",
    "    # filtered_response = re.sub(r'<think>.*?</think>\\s*', '', response, flags=re.DOTALL)\n",
    "    return response\n",
    "\n",
    "\n",
    "def load_chroma_db(\n",
    "    db_path=\"./rag_chroma\",\n",
    "    embedding=HuggingFaceEmbeddings(model_name=\"BAAI/bge-base-en\"),\n",
    "    collection_name=\"navie_rag\",\n",
    "):\n",
    "    chromadb = Chroma(embedding_function=embedding, persist_directory=db_path, collection_name=collection_name)\n",
    "    return chromadb\n",
    "\n",
    "\n",
    "def multi_query_search(query, db):\n",
    "\n",
    "    retriever = MultiQueryRetriever.from_llm(\n",
    "        retriever=db.as_retriever(), llm=OllamaLLM(model=\"qwen2.5:7b\"),include_original=True\n",
    "    )\n",
    "    print(\"retrieveing\")\n",
    "    return retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据库中的文档数量: 208\n",
      "文档ID列表: ['09ad5e4a-82e4-4a3c-870d-7957413150bc', '19badb6a-d660-49f0-bbb7-f7fdef9b7f88', 'efb7b018-165e-4e53-a2df-081a17ff4753', '63eb46ca-c6f0-43d0-add9-4ff1e5b87549', '211fdf87-c0f9-40cd-a1e4-3ae2ac881303', '0b3bbb2f-5e34-4340-9862-18205e8cd3cf', '55325bd3-348e-4ccb-9b3c-6611666ffebc', '1cf9b3f2-f470-47a9-88a2-53e3e283668d', '841e6e3c-881c-4f6a-b96c-df4bfb008aa4', 'fa8bc868-d3d4-42f4-ae96-56bf4da13e0e']\n",
      "\n",
      "示例文档内容:\n",
      "文档 1:\n",
      "内容: some also coverage except for the cruciforms. In contrast, Sequencer’s ERFs are limited to the\n",
      "cruciform and its neighborhood.\n",
      "It is interesting to note that Sequencer, with its characteristic ERFs, a...\n",
      "元数据: {'author': '', 'creationdate': '2023-01-13T02:09:12+00:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2023-01-13T02:09:12+00:00', 'page': 20, 'page_label': '21', 'producer': 'pdfTeX-1.40.21', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'source': 'lstm.pdf', 'subject': '', 'title': '', 'total_pages': 26, 'trapped': '/False'}\n",
      "\n",
      "文档 2:\n",
      "内容: some also coverage except for the cruciforms. In contrast, Sequencer’s ERFs are limited to the\n",
      "cruciform and its neighborhood.\n",
      "It is interesting to note that Sequencer, with its characteristic ERFs, a...\n",
      "元数据: {'author': '', 'creationdate': '2023-01-13T02:09:12+00:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2023-01-13T02:09:12+00:00', 'page': 20, 'page_label': '21', 'producer': 'pdfTeX-1.40.21', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'source': 'lstm.pdf', 'subject': '', 'title': '', 'total_pages': 26, 'trapped': '/False'}\n",
      "\n",
      "文档 3:\n",
      "内容: RVT-S* [53] 23M 4.7G 81.9 25.7 47.7 34.7 49.4 51.8 28.2 - -\n",
      "Sequencer2D-S 28M 8.4G 82.3 26.7 45.1 33.4 53.0 49.2 25.0 87.4 71.8\n",
      "Sequencer2D-M 38M 11.1G 82.8 30.5 46.3 34.7 51.8 50.8 26.3 87.6 72.5\n",
      "Swi...\n",
      "元数据: {'author': '', 'creationdate': '2023-01-13T02:09:12+00:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2023-01-13T02:09:12+00:00', 'page': 19, 'page_label': '20', 'producer': 'pdfTeX-1.40.21', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'source': 'lstm.pdf', 'subject': '', 'title': '', 'total_pages': 26, 'trapped': '/False'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "db = load_chroma_db()\n",
    "\n",
    "# 查看数据库内容\n",
    "print(\"数据库中的文档数量:\", db._collection.count())\n",
    "\n",
    "# 获取所有文档的ID\n",
    "all_ids = db._collection.get()[\"ids\"]\n",
    "print(\"文档ID列表:\", all_ids[:10] if len(all_ids) > 10 else all_ids)  # 只显示前10个ID\n",
    "\n",
    "# 获取数据库中的一些示例文档\n",
    "if db._collection.count() > 0:\n",
    "    sample_results = db.similarity_search(\"\", k=3)  # 随机获取几个文档\n",
    "    print(\"\\n示例文档内容:\")\n",
    "    for i, doc in enumerate(sample_results):\n",
    "        print(f\"文档 {i+1}:\")\n",
    "        print(f\"内容: {doc.page_content[:200]}...\" if len(doc.page_content) > 200 else doc.page_content)\n",
    "        print(f\"元数据: {doc.metadata}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieveing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(id='a6abc39e-15cd-4c89-9bcb-02f35f1a95c4', metadata={'author': '', 'creationdate': '2023-01-13T02:09:12+00:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2023-01-13T02:09:12+00:00', 'page': 2, 'page_label': '3', 'producer': 'pdfTeX-1.40.21', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'source': 'lstm.pdf', 'subject': '', 'title': '', 'total_pages': 26, 'trapped': '/False'}, page_content='of the proposed architectures.\\n3.1 Preliminaries: Long short-term memory\\nLSTM [27] is a specialized recurrent neural network (RNN) for modeling long-term dependencies of\\nsequences. Plain LSTM has an input gate it that controls the storage of inputs, a forget gate ft that\\ncontrols the forgetting of the former cell state ct−1 and an output gate ot that controls the cell output\\nht from the current cell state ct. Plain LSTM is formulated as follows:\\nit = σ(Wxixt + Whiht−1 + bi) , ft = σ(Wxf xt + Whf ht−1 + bf ) , (1)\\nct = ft ⊙ct−1 + it ⊙tanh (Wxcxt + Whcht−1 + bc) , ot = σ(Wxoxt + Whoht−1 + bo) , (2)\\nht = ot ⊙tanh(ct), (3)\\nwhere σis the logistic sigmoid function and ⊙is Hadamard product.\\n3'),\n",
       " Document(id='5b66e42b-5c64-4462-bf0d-2fff4a3c12c4', metadata={'author': '', 'creationdate': '2023-01-13T02:09:12+00:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2023-01-13T02:09:12+00:00', 'page': 2, 'page_label': '3', 'producer': 'pdfTeX-1.40.21', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'source': 'lstm.pdf', 'subject': '', 'title': '', 'total_pages': 26, 'trapped': '/False'}, page_content='of the proposed architectures.\\n3.1 Preliminaries: Long short-term memory\\nLSTM [27] is a specialized recurrent neural network (RNN) for modeling long-term dependencies of\\nsequences. Plain LSTM has an input gate it that controls the storage of inputs, a forget gate ft that\\ncontrols the forgetting of the former cell state ct−1 and an output gate ot that controls the cell output\\nht from the current cell state ct. Plain LSTM is formulated as follows:\\nit = σ(Wxixt + Whiht−1 + bi) , ft = σ(Wxf xt + Whf ht−1 + bf ) , (1)\\nct = ft ⊙ct−1 + it ⊙tanh (Wxcxt + Whcht−1 + bc) , ot = σ(Wxoxt + Whoht−1 + bo) , (2)\\nht = ot ⊙tanh(ct), (3)\\nwhere σis the logistic sigmoid function and ⊙is Hadamard product.\\n3'),\n",
       " Document(id='9b2d4942-23f7-4623-a474-0b3fd833abc5', metadata={'author': '', 'creationdate': '2023-01-13T02:09:12+00:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2023-01-13T02:09:12+00:00', 'page': 2, 'page_label': '3', 'producer': 'pdfTeX-1.40.21', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'source': 'lstm.pdf', 'subject': '', 'title': '', 'total_pages': 26, 'trapped': '/False'}, page_content='MorphMLP [86] have included similar ideas to improve efﬁciency and performance.\\nIn the early days of deep learning, there were attempts to use RNNs for image recognition. The\\nearliest study that applied RNNs to image recognition is [19]. The primary difference between our\\nstudy and [19] is that we utilize a usual RNN in place of a 2-multi-dimensional RNN(2MDRNN).\\nThe 2MDRNN requires H+ W sequential operations; The LSTM requires H sequential operations,\\nwhere H and W are height and width, respectively. For subsequent work on image recognition using\\n2MDRNNs, see [ 20, 32, 4, 43]. [4] proposed an architecture in which information is collected from\\nfour directions (upper left, lower left, upper right, and lower right) by RNNs for understanding natural\\nscene images. [43] proposed a novel 2MDRNN for semantic object parsing that integrates global and\\nlocal context information, called LG-LSTM. The overall architecture design is structured to input'),\n",
       " Document(id='eabe47fd-ff60-41ed-ad35-953f64db260a', metadata={'author': '', 'creationdate': '2023-01-13T02:09:12+00:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2023-01-13T02:09:12+00:00', 'page': 2, 'page_label': '3', 'producer': 'pdfTeX-1.40.21', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'source': 'lstm.pdf', 'subject': '', 'title': '', 'total_pages': 26, 'trapped': '/False'}, page_content='MorphMLP [86] have included similar ideas to improve efﬁciency and performance.\\nIn the early days of deep learning, there were attempts to use RNNs for image recognition. The\\nearliest study that applied RNNs to image recognition is [19]. The primary difference between our\\nstudy and [19] is that we utilize a usual RNN in place of a 2-multi-dimensional RNN(2MDRNN).\\nThe 2MDRNN requires H+ W sequential operations; The LSTM requires H sequential operations,\\nwhere H and W are height and width, respectively. For subsequent work on image recognition using\\n2MDRNNs, see [ 20, 32, 4, 43]. [4] proposed an architecture in which information is collected from\\nfour directions (upper left, lower left, upper right, and lower right) by RNNs for understanding natural\\nscene images. [43] proposed a novel 2MDRNN for semantic object parsing that integrates global and\\nlocal context information, called LG-LSTM. The overall architecture design is structured to input'),\n",
       " Document(id='70aa5021-31cb-4d22-930a-c7e5959b62ef', metadata={'author': '', 'creationdate': '2023-01-13T02:09:12+00:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2023-01-13T02:09:12+00:00', 'page': 14, 'page_label': '15', 'producer': 'pdfTeX-1.40.21', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'source': 'lstm.pdf', 'subject': '', 'title': '', 'total_pages': 26, 'trapped': '/False'}, page_content='# x: input tensor of shape (B, H, W, C)\\n### initialization ###\\nself.rnn_v = nn.LSTM(C, D, num_layers=1, batch_first=True, bias=True, bidirectional=True)\\nself.rnn_h = nn.LSTM(C, D, num_layers=1, batch_first=True, bias=True, bidirectional=True)\\nself.fc = nn.Linear(4 * D, C)\\n### forward ###\\ndef forward(self, x):\\nv, _ = self.rnn_v(x.permute(0, 2, 1, 3).reshape(-1, H, C))\\nv = v.reshape(B, W, H, -1).permute(0, 2, 1, 3)\\nh, _ = self.rnn_h(x.reshape(-1, W, C))\\nh = h.reshape(B, H, W, -1)\\nx = torch.cat([v, h], dim=-1)\\nx = self.fc(x)\\nreturn x\\nB.2 Architecture details\\nThis subsection describes Sequencer’s architecture. The architectural details are shown in Table 4\\nand 5.\\nSequencer2D-S is based on a ViP-S/7-like architecture. We intend to directly compare the BiLSTM2D\\nlayer in Sequencer2D, which has a similar structure, with the Permute-MLP layer in ViP-S/7. Table 4\\nis a summary of the architecture. In keeping with ViP, the ﬁrst stage of Sequencers involves patch'),\n",
       " Document(id='744c5a5a-8066-4a4d-867f-93ff02b543bd', metadata={'author': '', 'creationdate': '2023-01-13T02:09:12+00:00', 'creator': 'LaTeX with hyperref', 'keywords': '', 'moddate': '2023-01-13T02:09:12+00:00', 'page': 14, 'page_label': '15', 'producer': 'pdfTeX-1.40.21', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'source': 'lstm.pdf', 'subject': '', 'title': '', 'total_pages': 26, 'trapped': '/False'}, page_content='# x: input tensor of shape (B, H, W, C)\\n### initialization ###\\nself.rnn_v = nn.LSTM(C, D, num_layers=1, batch_first=True, bias=True, bidirectional=True)\\nself.rnn_h = nn.LSTM(C, D, num_layers=1, batch_first=True, bias=True, bidirectional=True)\\nself.fc = nn.Linear(4 * D, C)\\n### forward ###\\ndef forward(self, x):\\nv, _ = self.rnn_v(x.permute(0, 2, 1, 3).reshape(-1, H, C))\\nv = v.reshape(B, W, H, -1).permute(0, 2, 1, 3)\\nh, _ = self.rnn_h(x.reshape(-1, W, C))\\nh = h.reshape(B, H, W, -1)\\nx = torch.cat([v, h], dim=-1)\\nx = self.fc(x)\\nreturn x\\nB.2 Architecture details\\nThis subsection describes Sequencer’s architecture. The architectural details are shown in Table 4\\nand 5.\\nSequencer2D-S is based on a ViP-S/7-like architecture. We intend to directly compare the BiLSTM2D\\nlayer in Sequencer2D, which has a similar structure, with the Permute-MLP layer in ViP-S/7. Table 4\\nis a summary of the architecture. In keeping with ViP, the ﬁrst stage of Sequencers involves patch')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_query_search(\"what is LSTM?\", db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
